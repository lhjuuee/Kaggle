{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Humpback whale prediction using Resnet-50\n",
    "##### Ashish Patel in kaggle (Data Scientist at Softweb Solution. Ahmedabad, Gujarat, India)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import necessary library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda_\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.stats import logistic\n",
    "from os.path import join\n",
    "from PIL import Image\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input, Dense, Dropout, Lambda, Convolution2D, MaxPooling2D, Flatten\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Basic setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "embedding_dim = 50\n",
    "image_size = 224\n",
    "\n",
    "path_base = \"C:/Python/Whale_playground/\"\n",
    "path_train = join(path_base, 'train')\n",
    "path_test = join(path_base, 'test')\n",
    "path_model = join(path_base, 'MyModel.hdf5')\n",
    "path_csv = 'C:/Python/Whale_playground/train.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Define functions\n",
    "#### 3.1 sample_gen class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sample_gen(object):\n",
    "    \n",
    "    # 1. init function\n",
    "    \n",
    "    def __init__(self, file_class_mapping, other_class = \"new_whale\"):   # image value & Id\n",
    "        self.file_class_mapping = file_class_mapping\n",
    "        self.class_to_list_files = defaultdict(list)    # define nonexistent key for dictionary with default value\n",
    "        self.list_other_class = []\n",
    "        self.list_all_files = list(file_class_mapping.keys())    # key() -> extract keys of dictionary data as list\n",
    "        self.range_all_files = list(range(len(self.list_all_files)))\n",
    "        \n",
    "        for file, class_ in file_class_mapping.items():    # items() -> extract keys and values of dictionary data as list\n",
    "            if class_ == other_class:\n",
    "                self.list_other_class.append(file)    # fill 'image value' of new_whale for empty list defined before\n",
    "            else:\n",
    "                self.class_to_list_files[class_].append(file)    # fill 'image value' of specific_whale with 'Id value' for list\n",
    "        \n",
    "        self.list_classes = list(set(self.file_class_mapping.values()))    # set data type. No overlap, Unordered. For filtering overlap\n",
    "        self.range_list_classes = range(len(self.list_classes))    # range\n",
    "        \n",
    "        self.class_weight = np.array([len(self.class_to_list_files[class_]) for class_ in self.list_classes])\n",
    "        self.class_weight = self.class_weight / np.sum(self.class_weight)\n",
    "        \n",
    "    # 2. get_sample function    \n",
    "    \n",
    "    def get_sample(self):\n",
    "        class_idx = np.random.choice(self.range_list_classes, 1, p=self.class_weight)[0]\n",
    "        examples_class_idx = np.random.choice(range(len(self.class_to_list_files[self.list_classes[class_idx]])), 2)\n",
    "        positive_example_1, positive_example_2 = \\\n",
    "            self.class_to_list_files[self.list_classes[class_idx]][examples_class_idx[0]], \\\n",
    "            self.class_to_list_files[self.list_classes[class_idx]][examples_class_idx[1]]\n",
    "        \n",
    "        negative_example = None\n",
    "        while negative_example is None or self.file_class_mapping[negative_example] == \\\n",
    "                self.file_class_mapping[positive_example_1]:\n",
    "            negative_example_idx = np.random.choice(self.range_all_files, 1)[0]\n",
    "            negative_example = self.list_all_files[negative_example_idx]\n",
    "        return positive_example_1, negative_example, positive_example_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 other functions\n",
    "##### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. read_and_resize function\n",
    "    \n",
    "def read_and_resize(filepath):\n",
    "    im = Image.open((filepath)).convert('RGB')\n",
    "    im = im.resize((image_size, image_size))\n",
    "    return np.array(im, dtype=\"float32\")\n",
    "    \n",
    "# 2. augment function\n",
    "    \n",
    "def augment(im_array):\n",
    "    if np.random.uniform(0, 1) > 0.9:\n",
    "        im_array = np.fliplr(im_array)\n",
    "    return im_array\n",
    "    \n",
    "# 3. gen function\n",
    "    \n",
    "def gen(triplet_gen):\n",
    "    while True:\n",
    "        list_positive_examples_1 = []\n",
    "        list_negative_examples = []\n",
    "        list_positive_examples_2 = []\n",
    "            \n",
    "        for i in range(batch_size):\n",
    "            positive_example_1, negative_example, positive_example_2 = triplet_gen.get_sample()\n",
    "                \n",
    "            path_pos1 = join(path_train, positive_example_1)\n",
    "            path_neg = join(path_train, negative_example)\n",
    "            path_pos2 = join(path_train, positive_example_2)\n",
    "                \n",
    "            positive_example_1_img = read_and_resize(path_pos1)\n",
    "            negative_example_img = read_and_resize(path_neg)\n",
    "            positive_example_2_img = read_and_resize(path_pos2)\n",
    "                \n",
    "            positive_example_1_img = augment(positive_example_1_img)\n",
    "            negative_example_img = augment(negative_example_img)\n",
    "            positive_example_2_img = augment(positive_example_2_img)\n",
    "                \n",
    "            list_positive_examples_1.append(positive_example_1_img)\n",
    "            list_negative_examples.append(negative_example_img)\n",
    "            list_positive_examples_2.append(positive_example_2_img)\n",
    "                \n",
    "            \n",
    "        A = preprocess_input(np.array(list_positive_examples_1))\n",
    "        B = preprocess_input(np.array(list_positive_examples_2))\n",
    "        C = preprocess_input(np.array(list_negative_examples))\n",
    "            \n",
    "        label = None\n",
    "            \n",
    "        yield({'anchor_input': A, 'positive_input': B, 'negative_input': C}, label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
